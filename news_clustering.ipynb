{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/simoneritt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/simoneritt/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/simoneritt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DEFAULT_NUM_ARTICLES = 3\n",
    "\n",
    "START_DATE = '2025-03-01'\n",
    "END_DATE = '2025-03-03'\n",
    "INPUT_PATH = './news/news_2025_03.csv'\n",
    "OUTPUT_PATH = './result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.drop_duplicates(subset=['text'], keep='first', inplace=True)\n",
    "    df.drop_duplicates(subset=['title'], keep='first', inplace=True)\n",
    "    # df = df[df['text'].apply(len) > 800]\n",
    "    # df = df[df['text'].apply(len) < 10000]\n",
    "    # df = df[df['title'].str.contains('Opinion:') == False]\n",
    "    df = df.reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text data.\"\"\"\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [re.sub(r'[^a-zA-Z]', '', token.lower()) for token in tokens]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def vectorize_text(news_text, n_components=100):\n",
    "    \"\"\"\n",
    "    TF-IDF vectorization and dimension reducation of text data.\n",
    "    \"\"\"\n",
    "    print(\"Preprocessing text data...\")\n",
    "    preprocessed_text = [preprocess_text(text) for text in news_text]\n",
    "    \n",
    "    print(\"Vectorizing text data with TF-IDF...\")\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(preprocessed_text)\n",
    "    \n",
    "    if n_components and len(news_text) >= n_components:\n",
    "        print(\"Reducing dimensionality with PCA...\")\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X = pca.fit_transform(X.toarray())\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def adjust_dbscan_params(X, k=5):\n",
    "    \"\"\"\n",
    "    Adjust DBSCAN parameters `eps` and `min_samples` based on the dataset X.\n",
    "    \"\"\"\n",
    "    if X.shape[0] < k:\n",
    "        return 0.5, 2  # Default fallback for small datasets\n",
    "    \n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(X)\n",
    "    distances, _ = nbrs.kneighbors(X)\n",
    "    sorted_distances = np.sort(distances[:, k - 1], axis=0)\n",
    "    \n",
    "    eps = np.percentile(sorted_distances, 90)\n",
    "    min_samples = max(2, int(np.log(len(X))))\n",
    "    \n",
    "    print(f\"Adjusted DBSCAN Params â†’ eps: {eps:.4f}, min_samples: {min_samples}\")\n",
    "    return eps, min_samples\n",
    "\n",
    "\n",
    "def cluster_texts(X, eps=0.5, min_samples=3):\n",
    "    \"\"\"\n",
    "    Cluster vectorized news articles using DBSCAN.\n",
    "    \"\"\"\n",
    "    print(\"Clustering text data using DBSCAN...\")\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine')\n",
    "    dbscan.fit(X)\n",
    "    return dbscan.labels_\n",
    "\n",
    "\n",
    "def select_top_articles(data, labels, X, avg_distance_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Select top articles - one from each top-k valid clusters with largest cluster size.\n",
    "    Parameters:\n",
    "        - data (pd.DataFrame): The article dataset.\n",
    "        - labels (array): Cluster labels from DBSCAN.\n",
    "        - X (array): Cluster data points.\n",
    "        - avg_distance_threshold (float): Max average pairwise distance for valid clusters.\n",
    "    Returns:\n",
    "        - selected_articles (pd.DataFrame): Selected top articles.\n",
    "    \"\"\"\n",
    "    # Group indices by cluster\n",
    "    clusters = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        if label not in clusters:\n",
    "            clusters[label] = []\n",
    "        clusters[label].append(i)\n",
    "    \n",
    "    valid_clusters = []\n",
    "    \n",
    "    # Check for validity of each cluster based on average pairwise distance\n",
    "    for cluster_id, indices in clusters.items():\n",
    "        if cluster_id == -1 or len(indices) < 2:\n",
    "            continue  # Skip noise and tiny clusters\n",
    "        \n",
    "        cluster_points = X[indices]\n",
    "        avg_distance = np.mean(pairwise_distances(cluster_points, metric='cosine'))\n",
    "        \n",
    "        # Only consider clusters with avg_distance <= avg_distance_threshold\n",
    "        if avg_distance <= avg_distance_threshold:\n",
    "            valid_clusters.append((cluster_id, len(indices), avg_distance))\n",
    "    \n",
    "    # Sort valid clusters by size (descending)\n",
    "    valid_clusters = sorted(valid_clusters, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Sanity check\n",
    "    print(f\"--- Titles in Top-{DEFAULT_NUM_ARTICLES} Valid Clusters ---\")\n",
    "    for i, (cluster_id, size, avg_distance) in enumerate(valid_clusters[:DEFAULT_NUM_ARTICLES], start=1):\n",
    "        cluster_indices = [idx for idx, lbl in enumerate(labels) if lbl == cluster_id]\n",
    "        cluster_titles = data.iloc[cluster_indices]['title'].tolist()\n",
    "        print(f\"\\nCluster {i} (ID: {cluster_id}, Size: {size}, Avg Distance: {avg_distance:.4f}) Titles:\")\n",
    "        for title in cluster_titles:\n",
    "            print(f\"- {title}\")\n",
    "    print(\"--------------------------------------\\n\")\n",
    "    \n",
    "    selected_indices = set()\n",
    "    selected_articles = []\n",
    "    \n",
    "    # Pick one random article from each of the top-K valid clusters\n",
    "    for cluster_id, _, _ in valid_clusters[:DEFAULT_NUM_ARTICLES]:\n",
    "        idx = random.choice(clusters[cluster_id])\n",
    "        selected_indices.add(idx)\n",
    "        selected_articles.append(data.iloc[[idx]])\n",
    "    \n",
    "    # Add random articles if fewer than DEFAULT_NUM_ARTICLES are selected\n",
    "    while len(selected_articles) < DEFAULT_NUM_ARTICLES:\n",
    "        idx = random.randint(0, len(data) - 1)\n",
    "        if idx not in selected_indices:\n",
    "            selected_indices.add(idx)\n",
    "            selected_articles.append(data.iloc[[idx]])\n",
    "    \n",
    "    return pd.concat(selected_articles, ignore_index=True)\n",
    "\n",
    "\n",
    "def process_date(date, data, output_path):\n",
    "    \"\"\"\n",
    "    Process and save selected articles for a specific date.\n",
    "    \"\"\"\n",
    "    daily_data = data[data['date'] == date]\n",
    "    if daily_data.empty:\n",
    "        print(f\"No data for date: {date}\")\n",
    "        return\n",
    "    \n",
    "    news_text = daily_data['text'].tolist()\n",
    "    X = vectorize_text(news_text)\n",
    "    # eps, min_samples = adjust_dbscan_params(X)\n",
    "    eps, min_samples = 0.5, 3\n",
    "    labels = cluster_texts(X, eps=eps, min_samples=min_samples)\n",
    "    \n",
    "    # Sanity check - cluster statistics\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_points = list(labels).count(-1)\n",
    "    n_grouped_points = len(labels) - n_noise_points\n",
    "    total_samples = len(labels)\n",
    "    \n",
    "    print(f\"\\n--- Cluster Statistics ---\")\n",
    "    print(f\"Number of clusters: {n_clusters}\")\n",
    "    print(f\"Total number of samples: {total_samples}\")\n",
    "    print(f\"Number of grouped points: {n_grouped_points}\")\n",
    "    print(f\"Number of noise points: {n_noise_points}\")\n",
    "    print(\"---------------------------\\n\")\n",
    "    \n",
    "    selected_articles = select_top_articles(\n",
    "        daily_data,\n",
    "        labels,\n",
    "        X,\n",
    "        avg_distance_threshold=0.7\n",
    "    )\n",
    "    \n",
    "    save_path = os.path.join(output_path, date)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    selected_articles.to_csv(os.path.join(save_path, 'articles_selected.csv'), index=False)\n",
    "    print(f\"Articles for {date} saved successfully!\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = load_data(INPUT_PATH)\n",
    "    \n",
    "    start_date = datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(END_DATE, \"%Y-%m-%d\")\n",
    "    \n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "    \n",
    "    for current_date in tqdm(date_range, desc=\"Processing Dates\"):\n",
    "        date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "        print(f\"\\nProcessing date: {date_str}\")\n",
    "        process_date(date_str, data, OUTPUT_PATH) \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Dates:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-03-01\n",
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Dates:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text data with TF-IDF...\n",
      "Reducing dimensionality with PCA...\n",
      "Clustering text data using DBSCAN...\n",
      "\n",
      "--- Cluster Statistics ---\n",
      "Number of clusters: 7\n",
      "Total number of samples: 131\n",
      "Number of grouped points: 29\n",
      "Number of noise points: 102\n",
      "---------------------------\n",
      "\n",
      "--- Titles in Top-3 Valid Clusters ---\n",
      "\n",
      "Cluster 1 (ID: 0, Size: 11, Avg Distance: 0.4470) Titles:\n",
      "- Inside the 139 minutes that upended the US-Ukraine alliance\n",
      "- Zelensky says Trumpâ€™s backing is â€˜crucialâ€™ after US president berated him at White House\n",
      "- Trump objected to Zelenskyy's tone and body language in Oval Office clash, White House says\n",
      "- Zelenskyy seeks support at emergency European summit after bruising Trump encounter\n",
      "- NATO's Rutte urges Zelenskyy to mend his relationship with Trump\n",
      "- White House clash boosts pressure on Europe to aid Ukraine without U.S.\n",
      "- Opinion | Zelensky doesnâ€™t hold the cards. But he can still make a deal.\n",
      "- How the Trump-Zelensky Oval Office meeting spiraled into chaos\n",
      "- The debacle in the Oval leaves aid to Ukraine and peace deal hanging\n",
      "- Ukraine reels after Oval Office fracas, fears whatâ€™s next\n",
      "- European leaders renew support for Ukraine after Zelenskyy's stormy meeting with Trump\n",
      "\n",
      "Cluster 2 (ID: 1, Size: 3, Avg Distance: 0.0448) Titles:\n",
      "- Andrew Cuomo announces heâ€™s running for New York City mayor\n",
      "- Former New York Gov. Andrew Cuomo launches campaign for NYC mayor in bid to oust Eric Adams\n",
      "- In New York, a mayorâ€™s race takes shape thatâ€™s all about Donald Trump\n",
      "\n",
      "Cluster 3 (ID: 2, Size: 3, Avg Distance: 0.0144) Titles:\n",
      "- Gaza ceasefire hits expiration date with Israel and Hamas split on way forward\n",
      "- Israel and Hamas talks stall as Gaza ceasefire is set to expire\n",
      "- Hamas rejects Israel's request to extend phase one of Gaza ceasefire\n",
      "--------------------------------------\n",
      "\n",
      "Articles for 2025-03-01 saved successfully!\n",
      "\n",
      "Processing date: 2025-03-02\n",
      "Preprocessing text data...\n",
      "Vectorizing text data with TF-IDF...\n",
      "Reducing dimensionality with PCA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Dates:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering text data using DBSCAN...\n",
      "\n",
      "--- Cluster Statistics ---\n",
      "Number of clusters: 6\n",
      "Total number of samples: 111\n",
      "Number of grouped points: 23\n",
      "Number of noise points: 88\n",
      "---------------------------\n",
      "\n",
      "--- Titles in Top-3 Valid Clusters ---\n",
      "\n",
      "Cluster 1 (ID: 0, Size: 8, Avg Distance: 0.5255) Titles:\n",
      "- Europe seeks to take control of Ukraine negotiations, after Zelenskyâ€™s nightmare Trump visit sparks panic\n",
      "- White House amplifies rave reviews for Trumpâ€™s handling of Zelensky showdown as Europe rallies around Ukraine\n",
      "- Starmer says Europe faces a 'once in a generation moment' as leaders discuss ending war in Ukraine\n",
      "- After Trump clash, Ukraine's Zelenskyy gets warm UK welcome before European summit\n",
      "- European leaders â€˜doubling downâ€™ on backing Zelensky after Trump blowup\n",
      "- Zelensky should apologize to Trump to help Ukraine - The Washington Post\n",
      "- Trump-Zelensky meeting: The end of the geopolitical â€˜Westâ€™\n",
      "- UK prime minister unveils steps toward a Ukraine peace deal, urges US cooperation\n",
      "\n",
      "Cluster 2 (ID: 5, Size: 3, Avg Distance: 0.3136) Titles:\n",
      "- Zoe SaldaÃ±a dedicates her Oscar to her immigrant grandmother\n",
      "- Zoe SaldaÃ±a wins Oscar for best supporting actress in 'Emilia PÃ©rez'\n",
      "- 'Emilia PÃ©rez' actress Karla SofÃ­a GascÃ³n appears at the Oscars despite backlash\n",
      "\n",
      "Cluster 3 (ID: 1, Size: 3, Avg Distance: 0.1990) Titles:\n",
      "- Oscars winners list: See which nominees won an Academy Award (Updating Live)\n",
      "- Oscars 2025 live updates: Zoe Saldana wins for 'Emilia PÃ©rez,' 'Wicked' takes home design awards\n",
      "- Oscars 2025: The complete list of winners\n",
      "--------------------------------------\n",
      "\n",
      "Articles for 2025-03-02 saved successfully!\n",
      "\n",
      "Processing date: 2025-03-03\n",
      "Preprocessing text data...\n",
      "Vectorizing text data with TF-IDF...\n",
      "Reducing dimensionality with PCA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Dates: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering text data using DBSCAN...\n",
      "\n",
      "--- Cluster Statistics ---\n",
      "Number of clusters: 21\n",
      "Total number of samples: 271\n",
      "Number of grouped points: 159\n",
      "Number of noise points: 112\n",
      "---------------------------\n",
      "\n",
      "--- Titles in Top-3 Valid Clusters ---\n",
      "\n",
      "Cluster 1 (ID: 8, Size: 46, Avg Distance: 0.4418) Titles:\n",
      "- The crypto president has some ideas for your tax dollars\n",
      "- Bitcoin tumbles 9%, reversing most of the rally from Trump's crypto reserve announcement\n",
      "- Bitcoin gives back gains driven by President Trump's crypto reserve announcement: CNBC Crypto World\n",
      "- Leon Cooperman says he's selling into market strength and holding lots of cash\n",
      "- Southeast Asia and India are defining fintech around the world: Pine Labs CEO\n",
      "- Bitcoin erases gains from Trump's crypto reserve announcement\n",
      "- Watch Monday's full episode of Fast Money â€” March 3, 2025\n",
      "- Pantera's legal chief on how a U.S. crypto reserve could impact digital asset prices\n",
      "- Fast Money: SIEGY, GOOGL, MCHI, CI\n",
      "- Bitcoin gives back gains after Trump's proposed strategic crypto reserve\n",
      "- Target is under pressure because products are more discretionary, says TD Cowan's Oliver Chen\n",
      "- U.S. tariffs will cost typical American household at least $1,250 per year, Moodyâ€™s chief economist\n",
      "- Downdraft risks: CBOE's volatility head warns stock market is underpricing tariff impact\n",
      "- CNBC Markets Now: March 3, 2025\n",
      "- Post Market Wrap: March 3, 2025\n",
      "- 'Fast Money' traders talk the impact of tariffs on the markets\n",
      "- Crypto assets close sharply-lower\n",
      "- DeepSeek AI was a 'shot across the bow' for Nvidia, says Wedbush's Dan Ives\n",
      "- What is bad for Tesla may be good for the EV sector, says fmr. Tesla President Jon McNeill\n",
      "- Goldman's Greg Tuorto talks the Russell 2000 hitting six-month low\n",
      "- Bar for upside surprise is now a lot lower, says iCapital's Anastasia Amoroso\n",
      "- Notable Capital's Jeff Richards gives his read on the tech trade\n",
      "- This is a healthy pullback in tech, says J.P. Morgan Private Bank's Abigail Yoder\n",
      "- Watch CNBCâ€™s full interview with Solus' Dan Greenhaus, Requisiteâ€™s Bryn Talkington and Capital Area Planning's Malcolm Ethridge\n",
      "- Market uncertainty will continue to play out until there's more clarity, says Solus' Dan Greenhaus\n",
      "- Trump confirms that the 25% tariffs on Canada and Mexico will begin tomorrow\n",
      "- The tariff narrative needs to turn to stabilize markets, says Clearnomics' Lindsey Bell\n",
      "- A bitcoin trade using options if Trump's reserve puts a floor under crypto\n",
      "- Watch CNBCâ€™s full interview with Chinatalk podcastâ€™s Jordan Schneider and MCC Globalâ€™s Michelle Caruso-Cabrera\n",
      "- Watch CNBC's full discussion with the 'Squawk on the Street' crew\n",
      "- Watch CNBC's full interview with Omega Family Office chairman and CEO Leon Cooperman\n",
      "- Watch CNBC's full interview with Deutsche Telekom CEO: 'Europe has to wake up'\n",
      "- Watch CNBC's full interview with Fundstrat co-founder and managing partner Tom Lee\n",
      "- Watch Monday's full episode of the Halftime Report â€” March 3, 2025\n",
      "- The Economist's Zanny Minton Beddoes: European defense investors are anticipating too much, too soon\n",
      "- David Roche: â€˜NATO is deadâ€™ and Europe defense spending needs to increase\n",
      "- EU leaders gear up for a key meeting on defense financing\n",
      "- Increased defense spending would help Europe's fiscal position, says strategist\n",
      "- Investors should be 'careful' pricing defense stocks based on news flow: Goldman Sachs\n",
      "- Europe is squeezed by two 'overstated fears' of Russian aggression and American abandonment: BCA\n",
      "- WaFd Bank CEO on shifting away from single-family mortgage lending\n",
      "- We might see a reprieve on Canada and Mexico tariffs this week: Strategist\n",
      "- U.S. dollar strength might already be fully reflected in the price: CLSA\n",
      "- Final Trades: Taiwan Semi, Abbvie, Tradeweb Markets and the IYH\n",
      "- Trade Tracker: Steve Weiss sells out of Nvidia\n",
      "- Trade Tracker: Steve Weiss trims PDD Holdings, the KWEB and sells SLB\n",
      "\n",
      "Cluster 2 (ID: 0, Size: 22, Avg Distance: 0.6445) Titles:\n",
      "- Trump pauses military aid to Ukraine after Oval Office argument with Zelensky, White House official says\n",
      "- Analysis: Europeans embrace Zelensky after he was vilified by Trump\n",
      "- Trump officials suggest Zelensky should step aside. Hereâ€™s why thatâ€™s nearly impossible\n",
      "- Trumpâ€™s speech to Congress will be an explanation of his fast-paced first days in office\n",
      "- Visual guide of Trumpâ€™s guests and who is sitting where at the joint address\n",
      "- Trump continues to seethe at Zelensky as national security team gathers to discuss whatâ€™s next on Ukraine\n",
      "- European defense stocks hit record high after Trump and Zelenskyâ€™s disastrous meeting\n",
      "- Trump halts all U.S. military aid to Ukraine, White House official says\n",
      "- EU leaders prepare 'concrete' measures on defense financing, sources say\n",
      "- Europe wants to broker peace in Ukraine â€” and between Trump and Kyiv after the White House fiasco\n",
      "- European markets close higher after defense stocks surge\n",
      "- Trump administration to pause deliveries of military assistance to Ukraine, officials say\n",
      "- Ukrainians show off their â€˜suitsâ€™ after Trumpâ€™s criticism of Zelenskyâ€™s attire\n",
      "- Would Americans accept Trumpâ€™s concessions to Russia?\n",
      "- Trumpâ€™s digital disarmament favors Russia - The Washington Post\n",
      "- Trump administration to pause future deliveries of military aid to Ukraine\n",
      "- With his nation at war, Winston Churchill dressed in a wartime onesie\n",
      "- Top House Democrat says Trump is 'treating our allies as if they are our adversaries'\n",
      "- President Trump pauses Ukraine military aid\n",
      "- What you need to know about Trump's address to joint session of Congress\n",
      "- Poll: Majorities say state of the union is not strong, and Trump is rushing change\n",
      "- With Trump in office, U.S. allies lose standing, security\n",
      "\n",
      "Cluster 3 (ID: 3, Size: 17, Avg Distance: 0.6041) Titles:\n",
      "- Dow tumbles 650 points as Trump confirms tariffs on Mexico and Canada will start Tuesday\n",
      "- Trumpâ€™s tariff chaos threatens an economy already flashing yellow lights\n",
      "- Warren Buffett: Tariffs are â€˜an act of warâ€™\n",
      "- Why these companies are lowering prices despite rising inflation and looming tariffs\n",
      "- Trump dashes hopes for last-minute Canada and Mexico deal ahead of 25% tariffs\n",
      "- Trump tariffs will raise gasoline and electricity prices in the U.S., Canada energy minister says\n",
      "- Chipotle CEO says company will absorb any cost increases from tariffs\n",
      "- Auto giants scramble to suffer the least as Trump ramps up tariff threats\n",
      "- Chinese EV startup Xpeng delivers over 30,000 cars for a fourth straight month\n",
      "- 10-year Treasury yield slides as Trump reaffirms tariff policy\n",
      "- China says it will retaliate after Trump announces tariffs will double\n",
      "- Tariffs for Mexico and Canada begin Tuesday, Trump confirms\n",
      "- How China came to dominate the world in renewable energy\n",
      "- How China pulled ahead to become the world leader in electric vehicles\n",
      "- Hereâ€™s what could get more expensive under Trumpâ€™s tariffs\n",
      "- Auto industry braces for a blow from 25% tariffs on Canada and Mexico\n",
      "- Trump says 25% tariffs on imports from Canada and Mexico will go ahead\n",
      "--------------------------------------\n",
      "\n",
      "Articles for 2025-03-03 saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 3.69143 s\n",
      "File: /var/folders/tv/ry2w9b4n2p5bl45w_bdb30r80000gn/T/ipykernel_5683/1272839139.py\n",
      "Function: main at line 174\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   174                                           def main():\n",
      "   175         1  323480000.0    3e+08      8.8      data = load_data(INPUT_PATH)\n",
      "   176                                               \n",
      "   177         1      29000.0  29000.0      0.0      start_date = datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
      "   178         1       8000.0   8000.0      0.0      end_date = datetime.strptime(END_DATE, \"%Y-%m-%d\")\n",
      "   179                                               \n",
      "   180         1     141000.0 141000.0      0.0      date_range = pd.date_range(start=start_date, end=end_date)\n",
      "   181                                               \n",
      "   182         4    3256000.0 814000.0      0.1      for current_date in tqdm(date_range, desc=\"Processing Dates\"):\n",
      "   183         3      79000.0  26333.3      0.0          date_str = current_date.strftime(\"%Y-%m-%d\")\n",
      "   184         3      38000.0  12666.7      0.0          print(f\"\\nProcessing date: {date_str}\")\n",
      "   185         3 3364391000.0    1e+09     91.1          process_date(date_str, data, OUTPUT_PATH) \n",
      "   186                                               \n",
      "   187         1       4000.0   4000.0      0.0      return data"
     ]
    }
   ],
   "source": [
    "%lprun -f main data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text data...\n",
      "Vectorizing text data with TF-IDF...\n",
      "Reducing dimensionality with PCA...\n",
      "Clustering text data using DBSCAN...\n",
      "\n",
      "--- Cluster Statistics ---\n",
      "Number of clusters: 7\n",
      "Total number of samples: 131\n",
      "Number of grouped points: 30\n",
      "Number of noise points: 101\n",
      "---------------------------\n",
      "\n",
      "--- Titles in Top-3 Valid Clusters ---\n",
      "\n",
      "Cluster 1 (ID: 0, Size: 11, Avg Distance: 0.4411) Titles:\n",
      "- Inside the 139 minutes that upended the US-Ukraine alliance\n",
      "- Zelensky says Trumpâ€™s backing is â€˜crucialâ€™ after US president berated him at White House\n",
      "- Trump objected to Zelenskyy's tone and body language in Oval Office clash, White House says\n",
      "- Zelenskyy seeks support at emergency European summit after bruising Trump encounter\n",
      "- NATO's Rutte urges Zelenskyy to mend his relationship with Trump\n",
      "- White House clash boosts pressure on Europe to aid Ukraine without U.S.\n",
      "- Opinion | Zelensky doesnâ€™t hold the cards. But he can still make a deal.\n",
      "- How the Trump-Zelensky Oval Office meeting spiraled into chaos\n",
      "- The debacle in the Oval leaves aid to Ukraine and peace deal hanging\n",
      "- Ukraine reels after Oval Office fracas, fears whatâ€™s next\n",
      "- European leaders renew support for Ukraine after Zelenskyy's stormy meeting with Trump\n",
      "\n",
      "Cluster 2 (ID: 5, Size: 4, Avg Distance: 0.2785) Titles:\n",
      "- U.S. federal workers hit with second wave of emails demanding job details\n",
      "- Fresh Musk emails to workers lead to renewed pushback at federal agencies\n",
      "- As Musk polices his own conflicts, some agencies hear sirens going off\n",
      "- Federal workers get a new email demanding their accomplishments\n",
      "\n",
      "Cluster 3 (ID: 1, Size: 3, Avg Distance: 0.0400) Titles:\n",
      "- Andrew Cuomo announces heâ€™s running for New York City mayor\n",
      "- Former New York Gov. Andrew Cuomo launches campaign for NYC mayor in bid to oust Eric Adams\n",
      "- In New York, a mayorâ€™s race takes shape thatâ€™s all about Donald Trump\n",
      "--------------------------------------\n",
      "\n",
      "Articles for 2025-03-01 saved successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.893436 s\n",
      "File: /var/folders/tv/ry2w9b4n2p5bl45w_bdb30r80000gn/T/ipykernel_5683/1272839139.py\n",
      "Function: process_date at line 133\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   133                                           def process_date(date, data, output_path):\n",
      "   134                                               \"\"\"\n",
      "   135                                               Process and save selected articles for a specific date.\n",
      "   136                                               \"\"\"\n",
      "   137         1    1971000.0    2e+06      0.2      daily_data = data[data['date'] == date]\n",
      "   138         1      10000.0  10000.0      0.0      if daily_data.empty:\n",
      "   139                                                   print(f\"No data for date: {date}\")\n",
      "   140                                                   return\n",
      "   141                                               \n",
      "   142         1      76000.0  76000.0      0.0      news_text = daily_data['text'].tolist()\n",
      "   143         1  887522000.0    9e+08     99.3      X = vectorize_text(news_text)\n",
      "   144                                               # eps, min_samples = adjust_dbscan_params(X)\n",
      "   145         1       4000.0   4000.0      0.0      eps, min_samples = 0.5, 3\n",
      "   146         1    1212000.0    1e+06      0.1      labels = cluster_texts(X, eps=eps, min_samples=min_samples)\n",
      "   147                                               \n",
      "   148                                               # Sanity check - cluster statistics\n",
      "   149         1      12000.0  12000.0      0.0      n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
      "   150         1       7000.0   7000.0      0.0      n_noise_points = list(labels).count(-1)\n",
      "   151         1          0.0      0.0      0.0      n_grouped_points = len(labels) - n_noise_points\n",
      "   152         1          0.0      0.0      0.0      total_samples = len(labels)\n",
      "   153                                               \n",
      "   154         1       5000.0   5000.0      0.0      print(f\"\\n--- Cluster Statistics ---\")\n",
      "   155         1       2000.0   2000.0      0.0      print(f\"Number of clusters: {n_clusters}\")\n",
      "   156         1       2000.0   2000.0      0.0      print(f\"Total number of samples: {total_samples}\")\n",
      "   157         1       2000.0   2000.0      0.0      print(f\"Number of grouped points: {n_grouped_points}\")\n",
      "   158         1       2000.0   2000.0      0.0      print(f\"Number of noise points: {n_noise_points}\")\n",
      "   159         1       2000.0   2000.0      0.0      print(\"---------------------------\\n\")\n",
      "   160                                               \n",
      "   161         2    1962000.0 981000.0      0.2      selected_articles = select_top_articles(\n",
      "   162         1          0.0      0.0      0.0          daily_data,\n",
      "   163         1          0.0      0.0      0.0          labels,\n",
      "   164         1          0.0      0.0      0.0          X,\n",
      "   165         1          0.0      0.0      0.0          avg_distance_threshold=0.7\n",
      "   166                                               )\n",
      "   167                                               \n",
      "   168         1       5000.0   5000.0      0.0      save_path = os.path.join(output_path, date)\n",
      "   169         1      31000.0  31000.0      0.0      os.makedirs(save_path, exist_ok=True)\n",
      "   170         1     604000.0 604000.0      0.1      selected_articles.to_csv(os.path.join(save_path, 'articles_selected.csv'), index=False)\n",
      "   171         1       5000.0   5000.0      0.0      print(f\"Articles for {date} saved successfully!\")"
     ]
    }
   ],
   "source": [
    "%lprun -f process_date process_date('2025-03-01', data, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
